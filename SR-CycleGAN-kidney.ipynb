{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:48.459792Z",
     "iopub.status.busy": "2021-06-16T15:58:48.459177Z",
     "iopub.status.idle": "2021-06-16T15:58:50.005450Z",
     "shell.execute_reply": "2021-06-16T15:58:50.005901Z"
    },
    "id": "lhSsUx9Nyb3t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:50.010723Z",
     "iopub.status.busy": "2021-06-16T15:58:50.009899Z",
     "iopub.status.idle": "2021-06-16T15:58:50.775618Z",
     "shell.execute_reply": "2021-06-16T15:58:50.776069Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix_4xSR as pix2pix\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "   print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.740028Z",
     "iopub.status.busy": "2021-06-16T15:58:55.739357Z",
     "iopub.status.idle": "2021-06-16T15:58:55.741688Z",
     "shell.execute_reply": "2021-06-16T15:58:55.741235Z"
    },
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100\n",
    "BATCH_SIZE = 16\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "ratio=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lr(image_file):\n",
    "  image = tf.io.read_file(image_file)\n",
    "  image = tf.image.decode_png(image)\n",
    "\n",
    "#   low_image_up=tf.image.resize(image,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "\n",
    "  input_image = tf.cast(image, tf.float32)  \n",
    "  input_image=tf.reshape(input_image,[int(IMG_WIDTH/4),int(IMG_HEIGHT/4),3])\n",
    "\n",
    "  \n",
    "  return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr(image_file):\n",
    "  image = tf.io.read_file(image_file)\n",
    "  image = tf.image.decode_png(image)\n",
    "\n",
    "  \n",
    "  real_image = tf.cast(image, tf.float32)\n",
    "  real_image=tf.reshape(real_image,[IMG_WIDTH,IMG_HEIGHT,3])\n",
    "  \n",
    "  return real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=load_lr('/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_64_train/pair5&20_50_74.png')\n",
    "re = load_hr('/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_256_train/pair5&20_50_85.png')\n",
    "\n",
    "# casting to int for matplotlib to show the image\n",
    "plt.figure()\n",
    "plt.imshow(inp[:,:]/255.0,cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(re[:,:]/255.0,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.746047Z",
     "iopub.status.busy": "2021-06-16T15:58:55.745375Z",
     "iopub.status.idle": "2021-06-16T15:58:55.747740Z",
     "shell.execute_reply": "2021-06-16T15:58:55.747243Z"
    },
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.751658Z",
     "iopub.status.busy": "2021-06-16T15:58:55.751024Z",
     "iopub.status.idle": "2021-06-16T15:58:55.753310Z",
     "shell.execute_reply": "2021-06-16T15:58:55.752817Z"
    },
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.757651Z",
     "iopub.status.busy": "2021-06-16T15:58:55.757033Z",
     "iopub.status.idle": "2021-06-16T15:58:55.759103Z",
     "shell.execute_reply": "2021-06-16T15:58:55.758573Z"
    },
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.762984Z",
     "iopub.status.busy": "2021-06-16T15:58:55.762351Z",
     "iopub.status.idle": "2021-06-16T15:58:55.765159Z",
     "shell.execute_reply": "2021-06-16T15:58:55.764683Z"
    },
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_lr(image):\n",
    "#   image = random_jitter(image)\n",
    "  image=load_lr(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.769351Z",
     "iopub.status.busy": "2021-06-16T15:58:55.768717Z",
     "iopub.status.idle": "2021-06-16T15:58:55.771212Z",
     "shell.execute_reply": "2021-06-16T15:58:55.770606Z"
    },
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_hr(image):\n",
    "  image=load_hr(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_64_train'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "train_dataset_lr = tf.data.Dataset.list_files(PATH+'/*.png')\n",
    "train_dataset_lr = train_dataset_lr.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset_lr = train_dataset_lr.shuffle(BUFFER_SIZE)\n",
    "train_dataset_lr = train_dataset_lr.batch(BATCH_SIZE)\n",
    "train_dataset_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_256_train'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "train_dataset_hr = tf.data.Dataset.list_files(PATH+'/*.png')\n",
    "train_dataset_hr = train_dataset_hr.map(preprocess_image_hr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset_hr = train_dataset_hr.shuffle(BUFFER_SIZE)\n",
    "train_dataset_hr = train_dataset_hr.batch(BATCH_SIZE)\n",
    "train_dataset_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_64_test'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_lr = tf.data.Dataset.list_files(PATH+'/*.png')\n",
    "test_dataset_lr = test_dataset_lr.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_lr = test_dataset_lr.shuffle(BUFFER_SIZE)\n",
    "test_dataset_lr = test_dataset_lr.batch(BATCH_SIZE)\n",
    "test_dataset_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_256_test'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_hr = tf.data.Dataset.list_files(PATH+'/*.png')\n",
    "test_dataset_hr = test_dataset_hr.map(preprocess_image_hr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_hr = test_dataset_hr.shuffle(BUFFER_SIZE)\n",
    "test_dataset_hr = test_dataset_hr.batch(BATCH_SIZE)\n",
    "test_dataset_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:58:55.980883Z",
     "iopub.status.busy": "2021-06-16T15:58:55.980080Z",
     "iopub.status.idle": "2021-06-16T15:59:04.840410Z",
     "shell.execute_reply": "2021-06-16T15:59:04.839029Z"
    },
    "id": "e3MhJ3zVLPan"
   },
   "outputs": [],
   "source": [
    "sample_lr = next(iter(train_dataset_lr))\n",
    "sample_hr = next(iter(train_dataset_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:04.880253Z",
     "iopub.status.busy": "2021-06-16T15:59:04.869488Z",
     "iopub.status.idle": "2021-06-16T15:59:05.418855Z",
     "shell.execute_reply": "2021-06-16T15:59:05.419271Z"
    },
    "id": "4pOYjMk_KfIB"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('lr')\n",
    "plt.imshow(sample_lr[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('lr with random jitter')\n",
    "plt.imshow(random_jitter(sample_lr[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:05.442237Z",
     "iopub.status.busy": "2021-06-16T15:59:05.441560Z",
     "iopub.status.idle": "2021-06-16T15:59:05.655264Z",
     "shell.execute_reply": "2021-06-16T15:59:05.655688Z"
    },
    "id": "0KJyB9ENLb2y"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('hr')\n",
    "plt.imshow(sample_hr[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('hr with random jitter')\n",
    "plt.imshow(random_jitter(sample_hr[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## SR-CycleGAN model with two generators and two discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:05.660872Z",
     "iopub.status.busy": "2021-06-16T15:59:05.660187Z",
     "iopub.status.idle": "2021-06-16T15:59:07.075730Z",
     "shell.execute_reply": "2021-06-16T15:59:07.075142Z"
    },
    "id": "8ju9Wyw87MRW"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator_lr(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator_hr(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:07.082503Z",
     "iopub.status.busy": "2021-06-16T15:59:07.081817Z",
     "iopub.status.idle": "2021-06-16T15:59:09.497692Z",
     "shell.execute_reply": "2021-06-16T15:59:09.498123Z"
    },
    "id": "wDaGZ3WpZUyw"
   },
   "outputs": [],
   "source": [
    "sample_lr_up=tf.image.resize(sample_lr,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "to_hr = generator_g(sample_lr_up)\n",
    "to_lr = generator_f(sample_hr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_lr, to_hr, sample_hr, to_lr]\n",
    "title = ['LR', 'To HR', 'HR', 'To LR']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i])\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "  else:\n",
    "    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.523516Z",
     "iopub.status.busy": "2021-06-16T15:59:09.522818Z",
     "iopub.status.idle": "2021-06-16T15:59:09.746354Z",
     "shell.execute_reply": "2021-06-16T15:59:09.745876Z"
    },
    "id": "O5MhJmxyZiy9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real HR?')\n",
    "plt.imshow(discriminator_y(sample_hr)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real LR?')\n",
    "plt.imshow(discriminator_x(sample_lr)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.750633Z",
     "iopub.status.busy": "2021-06-16T15:59:09.749930Z",
     "iopub.status.idle": "2021-06-16T15:59:09.752399Z",
     "shell.execute_reply": "2021-06-16T15:59:09.751952Z"
    },
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.756093Z",
     "iopub.status.busy": "2021-06-16T15:59:09.755440Z",
     "iopub.status.idle": "2021-06-16T15:59:09.757465Z",
     "shell.execute_reply": "2021-06-16T15:59:09.757816Z"
    },
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.761975Z",
     "iopub.status.busy": "2021-06-16T15:59:09.761296Z",
     "iopub.status.idle": "2021-06-16T15:59:09.763419Z",
     "shell.execute_reply": "2021-06-16T15:59:09.763782Z"
    },
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "  real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.767507Z",
     "iopub.status.busy": "2021-06-16T15:59:09.766764Z",
     "iopub.status.idle": "2021-06-16T15:59:09.768815Z",
     "shell.execute_reply": "2021-06-16T15:59:09.769159Z"
    },
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "  return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.773001Z",
     "iopub.status.busy": "2021-06-16T15:59:09.772351Z",
     "iopub.status.idle": "2021-06-16T15:59:09.775016Z",
     "shell.execute_reply": "2021-06-16T15:59:09.774394Z"
    },
    "id": "NMpVGj_sW6Vo"
   },
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "  \n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.779032Z",
     "iopub.status.busy": "2021-06-16T15:59:09.778382Z",
     "iopub.status.idle": "2021-06-16T15:59:09.780415Z",
     "shell.execute_reply": "2021-06-16T15:59:09.780787Z"
    },
    "id": "05ywEH680Aud"
   },
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "  return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.785540Z",
     "iopub.status.busy": "2021-06-16T15:59:09.784820Z",
     "iopub.status.idle": "2021-06-16T15:59:09.786913Z",
     "shell.execute_reply": "2021-06-16T15:59:09.787264Z"
    },
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.2)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.2)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.2)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.792651Z",
     "iopub.status.busy": "2021-06-16T15:59:09.792002Z",
     "iopub.status.idle": "2021-06-16T15:59:09.793984Z",
     "shell.execute_reply": "2021-06-16T15:59:09.794365Z"
    },
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/hzhuge/Downloads/SR_2D/checkpoints_SR-Cycgan_kidney'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.797897Z",
     "iopub.status.busy": "2021-06-16T15:59:09.797277Z",
     "iopub.status.idle": "2021-06-16T15:59:09.799667Z",
     "shell.execute_reply": "2021-06-16T15:59:09.799192Z"
    },
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.804588Z",
     "iopub.status.busy": "2021-06-16T15:59:09.803943Z",
     "iopub.status.idle": "2021-06-16T15:59:09.806173Z",
     "shell.execute_reply": "2021-06-16T15:59:09.805747Z"
    },
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "  prediction = model(test_input)\n",
    "    \n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_input[0], prediction[0]]\n",
    "  title = ['Input Image', 'Predicted Image']\n",
    "  \n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.title(title[0])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "  plt.imshow(test_input[0] * 0.5 + 0.5)\n",
    "  plt.axis('off')\n",
    "  \n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.title(title[1])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "  plt.imshow(prediction[0] * 0.5 + 0.5)\n",
    "  plt.axis('off')\n",
    "    \n",
    "  plt.show()\n",
    "#   for i in range(2):\n",
    "#     plt.subplot(1, 2, i+1)\n",
    "#     plt.title(title[i])\n",
    "#     # getting the pixel values between [0, 1] to plot it.\n",
    "#     plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "#     plt.axis('off')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE47ERn5fyLC"
   },
   "source": [
    "Even though the training loop looks complicated, it consists of four basic steps:\n",
    "\n",
    "* Get the predictions.\n",
    "* Calculate the loss.\n",
    "* Calculate the gradients using backpropagation.\n",
    "* Apply the gradients to the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.814364Z",
     "iopub.status.busy": "2021-06-16T15:59:09.813637Z",
     "iopub.status.idle": "2021-06-16T15:59:09.816129Z",
     "shell.execute_reply": "2021-06-16T15:59:09.815671Z"
    },
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "  # persistent is set to True because the tape is used more than\n",
    "  # once to calculate the gradients.\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    # Generator G translates X -> Y\n",
    "    # Generator F translates Y -> X.\n",
    "    real_x_up=tf.image.resize(real_x,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "    fake_y = generator_g(real_x_up, training=True)\n",
    "    cycled_x = generator_f(fake_y, training=True)\n",
    "    cycled_x_down=tf.image.resize(cycled_x,[64,64],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "    \n",
    "    fake_x = generator_f(real_y, training=True)\n",
    "    fake_x_down=tf.image.resize(fake_x,[64,64],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "    cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "    # same_x and same_y are used for identity loss.\n",
    "    same_x = generator_f(real_x_up, training=True)\n",
    "    same_x_down=tf.image.resize(same_x,[64,64],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "\n",
    "    same_y = generator_g(real_y, training=True)\n",
    "\n",
    "    disc_real_x = discriminator_x(real_x, training=True)\n",
    "    disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "    disc_fake_x = discriminator_x(fake_x_down, training=True)\n",
    "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "    # calculate the loss\n",
    "    gen_g_loss = generator_loss(disc_fake_y)\n",
    "    gen_f_loss = generator_loss(disc_fake_x)\n",
    "    \n",
    "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x_down) + calc_cycle_loss(real_y, cycled_y)\n",
    "    \n",
    "    # Total generator loss = adversarial loss + cycle loss\n",
    "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x_down)\n",
    "\n",
    "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "  \n",
    "  # Calculate the gradients for generator and discriminator\n",
    "  generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "  generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "  \n",
    "  discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "  discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer\n",
    "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "  \n",
    "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "  \n",
    "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:59:09.821603Z",
     "iopub.status.busy": "2021-06-16T15:59:09.820996Z",
     "iopub.status.idle": "2021-06-16T17:49:38.390812Z",
     "shell.execute_reply": "2021-06-16T17:49:38.390381Z"
    },
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1,1000):\n",
    "  start = time.time()\n",
    "\n",
    "  n = 0\n",
    "  for image_x, image_y in tf.data.Dataset.zip((train_dataset_lr, train_dataset_hr)):\n",
    "    train_step(image_x, image_y)\n",
    "    if n % 10 == 0:\n",
    "      print ('.', end='')\n",
    "    n += 1\n",
    "\n",
    "  clear_output(wait=True)\n",
    "  # Using a consistent image (sample_horse) so that the progress of the model\n",
    "  # is clearly visible.\n",
    "  sample_lr_up=tf.image.resize(sample_lr,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "  generate_images(generator_g, sample_lr_up)\n",
    "\n",
    "  if (epoch + 1) % 100 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "\n",
    "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "## Generate using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {checkpoint_path} \n",
    "checkpoint_path\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:49:38.395666Z",
     "iopub.status.busy": "2021-06-16T17:49:38.395059Z",
     "iopub.status.idle": "2021-06-16T17:49:40.872218Z",
     "shell.execute_reply": "2021-06-16T17:49:40.872593Z"
    },
    "id": "KUgSnmy2nqSP"
   },
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in test_dataset_lr.take(20):\n",
    "  sample_lr_up=tf.image.resize(inp,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "  generate_images(generator_g, sample_lr_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/breast/patch_64_test'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_lr_name = tf.data.Dataset.list_files(PATH+'/*.png',shuffle=False)\n",
    "test_dataset_lr = test_dataset_lr_name.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_lr = test_dataset_lr.batch(1)\n",
    "test_dataset_lr\n",
    "\n",
    "import re\n",
    "subname=list()\n",
    "for filename in test_dataset_lr_name:\n",
    "  fname=filename.numpy().decode('utf-8')\n",
    "  res=re.split(\"[/.]\",fname)[-2]\n",
    "  subname.append(res) \n",
    "\n",
    "subname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(hgram):\n",
    "...     \"\"\" Mutual information for joint histogram\n",
    "...     \"\"\"\n",
    "...     # Convert bins counts to probability values\n",
    "...     pxy = hgram / float(np.sum(hgram))\n",
    "...     px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "...     py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "...     px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals\n",
    "...     # Now we can do the calculation using the pxy, px_py 2D arrays\n",
    "...     nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "...     return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_mse_mi(model, test_input,index):\n",
    "  # the training=True is intentional here since\n",
    "  # we want the batch statistics while running the model\n",
    "  # on the test dataset. If we use training=False, we will get\n",
    "  # the accumulated statistics learned from the training dataset\n",
    "  # (which we don't want)\n",
    "#   filename_cnn=subname[index]+'.png'\n",
    "#   directory_predict_unet = r'/home/hzhuge/Downloads/CSBDeep-master/examples/denoising2D/phantom_data/predict'  \n",
    "#   unet=tf.image.decode_image(tf.io.read_file(unet_name))\n",
    "#   unet = tf.expand_dims(tf.cast(unet[:,:,0], tf.float32),axis=2)\n",
    "\n",
    "\n",
    "  prediction = model(test_input, training=True)\n",
    "  print(prediction.shape)\n",
    "  plt.figure(figsize=(20,20))\n",
    "  \n",
    " \n",
    "  filename=subname[index]+'.png'\n",
    "  path_hr='/home/hzhuge/Downloads/SR_2D/cycgan_patch/breast/patch_256'\n",
    "  PATH=os.path.join(path_hr,filename)\n",
    "  test_hr = preprocess_image_hr(PATH)\n",
    "\n",
    "\n",
    "    \n",
    "  display_list = [test_input[0], test_hr, prediction[0]]\n",
    "  title = ['Gaussian', 'Ground Truth', 'Predicted Image_CycleGAN']\n",
    "  inputim_l=np.array(display_list[0]*0.5+0.5)\n",
    "  ground_l=np.array(display_list[1]*0.5+0.5)\n",
    "  predict_l=np.array(display_list[2]*0.5+0.5)\n",
    "  \n",
    "  \n",
    "  inputim_g= display_list[0]*0.5+0.5\n",
    "  ground_g = display_list[1]*0.5+0.5\n",
    "  predict_g = display_list[2]*0.5+0.5\n",
    " \n",
    "  \n",
    "# sim vs. wide-field\n",
    "  mgi=np.square(np.subtract(ground_l, inputim_l)).mean()\n",
    "  sgi=tf.image.ssim(ground_g,inputim_g, max_val=1.0).numpy()\n",
    "  hist_2d_gi, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gi=mutual_information(hist_2d_gi)\n",
    "    \n",
    "# sim vs. gan\n",
    "  mgp=np.square(np.subtract(ground_l, predict_l)).mean()\n",
    "  sgp=tf.image.ssim(ground_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_gp, x_edges, y_edges = np.histogram2d(predict_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gp=mutual_information(hist_2d_gp)\n",
    "\n",
    "\n",
    "# wide_field vs.gan\n",
    "  mip=np.square(np.subtract(inputim_l, predict_l)).mean()\n",
    "  sip=tf.image.ssim(inputim_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_ip, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),predict_l.ravel(),bins=20)\n",
    "  mi_ip=mutual_information(hist_2d_ip)\n",
    "\n",
    "\n",
    "#  df = pd.DataFrame(np.array([mgi,mgp,mip,sgi,sgp,sip]), columns =['mse_ground_input','mse_ground_predict','mse_input_predict','ssim_ground_input',\n",
    "#           'ssim_ground_predict','ssim_input_predict']) \n",
    "  d={\n",
    "     \n",
    "     'MSE_HR_CycleGAN':mgp,\n",
    "     'MSE_HR_Gaussian':mgi,\n",
    "     'MSE_Gaussian_CycleGAN':mip,\n",
    "    \n",
    "     'SSIM_HR_CycleGAN':sgp,\n",
    "     'SSIM_HR_Gaussian':sgi,\n",
    "     'SSIM_Gaussian_CycleGAN':sip,\n",
    "    \n",
    "     'MI_HR_CycleGAN':mi_gp,\n",
    "     'MI_HR_Gaussian':mi_gi,\n",
    "     'MI_Gaussian_CycleGAN':mi_ip,\n",
    "     }\n",
    "#   d={'MSE_HR_GAN':mgp,\n",
    "#      'MSE_LR_GAN':mip,\n",
    "#      'MSE_LR_HR':mgi,\n",
    "#      'SSIM_HR_GAN':sgp,\n",
    "#      'SSIM_LR_GAN':sip,\n",
    "#      'SSIM_LR_HR':sgi,\n",
    "#      'MI_HR_GAN':mi_gp,\n",
    "#      'MI_LR_GAN':mi_ip,\n",
    "#      'MI_LR_HR':mi_gi}\n",
    "  ps1=pd.Series(d).to_frame().T\n",
    "  ps=pd.Series(d)\n",
    "  \n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "    \n",
    "\n",
    "  print(ps)\n",
    "  return ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "i=0\n",
    "df=pd.DataFrame()\n",
    "# Run the trained model on the test dataset\n",
    "for inp in test_dataset_lr.take(30):\n",
    "  ps=ssim_mse_mi(generator_g, inp,i)\n",
    "  df_temp=pd.DataFrame(ps)\n",
    "  df=df.append(df_temp)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/prostate/patch_64_train'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_lr_name = tf.data.Dataset.list_files(PATH+'/*.png',shuffle=False)\n",
    "test_dataset_lr = test_dataset_lr_name.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_lr = test_dataset_lr.batch(1)\n",
    "test_dataset_lr\n",
    "\n",
    "import re\n",
    "subname=list()\n",
    "for filename in test_dataset_lr_name:\n",
    "  fname=filename.numpy().decode('utf-8')\n",
    "  res=re.split(\"[/.]\",fname)[-2]\n",
    "  subname.append(res) \n",
    "\n",
    "subname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_mse_mi(model, test_input,index):\n",
    "  # the training=True is intentional here since\n",
    "  # we want the batch statistics while running the model\n",
    "  # on the test dataset. If we use training=False, we will get\n",
    "  # the accumulated statistics learned from the training dataset\n",
    "  # (which we don't want)\n",
    "#   filename_cnn=subname[index]+'.png'\n",
    "#   directory_predict_unet = r'/home/hzhuge/Downloads/CSBDeep-master/examples/denoising2D/phantom_data/predict'  \n",
    "#   unet=tf.image.decode_image(tf.io.read_file(unet_name))\n",
    "#   unet = tf.expand_dims(tf.cast(unet[:,:,0], tf.float32),axis=2)\n",
    "\n",
    "\n",
    "  prediction = model(test_input, training=True)\n",
    "  print(prediction.shape)\n",
    "  plt.figure(figsize=(20,20))\n",
    "  \n",
    " \n",
    "  filename=subname[index]+'.png'\n",
    "  path_hr='/home/hzhuge/Downloads/SR_2D/cycgan_patch/prostate/patch_256'\n",
    "  PATH=os.path.join(path_hr,filename)\n",
    "  test_hr = preprocess_image_hr(PATH)\n",
    "\n",
    "\n",
    "    \n",
    "  display_list = [test_input[0], test_hr, prediction[0]]\n",
    "  title = ['Gaussian', 'Ground Truth', 'Predicted Image_CycleGAN']\n",
    "  inputim_l=np.array(display_list[0]*0.5+0.5)\n",
    "  ground_l=np.array(display_list[1]*0.5+0.5)\n",
    "  predict_l=np.array(display_list[2]*0.5+0.5)\n",
    "  \n",
    "  \n",
    "  inputim_g= display_list[0]*0.5+0.5\n",
    "  ground_g = display_list[1]*0.5+0.5\n",
    "  predict_g = display_list[2]*0.5+0.5\n",
    " \n",
    "  \n",
    "# sim vs. wide-field\n",
    "  mgi=np.square(np.subtract(ground_l, inputim_l)).mean()\n",
    "  sgi=tf.image.ssim(ground_g,inputim_g, max_val=1.0).numpy()\n",
    "  hist_2d_gi, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gi=mutual_information(hist_2d_gi)\n",
    "    \n",
    "# sim vs. gan\n",
    "  mgp=np.square(np.subtract(ground_l, predict_l)).mean()\n",
    "  sgp=tf.image.ssim(ground_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_gp, x_edges, y_edges = np.histogram2d(predict_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gp=mutual_information(hist_2d_gp)\n",
    "\n",
    "\n",
    "# wide_field vs.gan\n",
    "  mip=np.square(np.subtract(inputim_l, predict_l)).mean()\n",
    "  sip=tf.image.ssim(inputim_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_ip, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),predict_l.ravel(),bins=20)\n",
    "  mi_ip=mutual_information(hist_2d_ip)\n",
    "\n",
    "\n",
    "#  df = pd.DataFrame(np.array([mgi,mgp,mip,sgi,sgp,sip]), columns =['mse_ground_input','mse_ground_predict','mse_input_predict','ssim_ground_input',\n",
    "#           'ssim_ground_predict','ssim_input_predict']) \n",
    "  d={\n",
    "     \n",
    "     'MSE_HR_CycleGAN':mgp,\n",
    "     'MSE_HR_Gaussian':mgi,\n",
    "     'MSE_Gaussian_CycleGAN':mip,\n",
    "    \n",
    "     'SSIM_HR_CycleGAN':sgp,\n",
    "     'SSIM_HR_Gaussian':sgi,\n",
    "     'SSIM_Gaussian_CycleGAN':sip,\n",
    "    \n",
    "     'MI_HR_CycleGAN':mi_gp,\n",
    "     'MI_HR_Gaussian':mi_gi,\n",
    "     'MI_Gaussian_CycleGAN':mi_ip,\n",
    "     }\n",
    "#   d={'MSE_HR_GAN':mgp,\n",
    "#      'MSE_LR_GAN':mip,\n",
    "#      'MSE_LR_HR':mgi,\n",
    "#      'SSIM_HR_GAN':sgp,\n",
    "#      'SSIM_LR_GAN':sip,\n",
    "#      'SSIM_LR_HR':sgi,\n",
    "#      'MI_HR_GAN':mi_gp,\n",
    "#      'MI_LR_GAN':mi_ip,\n",
    "#      'MI_LR_HR':mi_gi}\n",
    "  ps1=pd.Series(d).to_frame().T\n",
    "  ps=pd.Series(d)\n",
    "  \n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "    \n",
    "\n",
    "  print(ps)\n",
    "  return ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "i=0\n",
    "df=pd.DataFrame()\n",
    "# Run the trained model on the test dataset\n",
    "for inp in test_dataset_lr.take(30):\n",
    "  ps=ssim_mse_mi(generator_g, inp,i)\n",
    "  df_temp=pd.DataFrame(ps)\n",
    "  df=df.append(df_temp)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_64_test'\n",
    "#datadir='/home/hzhuge/Downloads/1072case/'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_lr_name = tf.data.Dataset.list_files(PATH+'/*.png',shuffle=False)\n",
    "test_dataset_lr = test_dataset_lr_name.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_lr = test_dataset_lr.batch(1)\n",
    "test_dataset_lr\n",
    "\n",
    "import re\n",
    "subname=list()\n",
    "for filename in test_dataset_lr_name:\n",
    "  fname=filename.numpy().decode('utf-8')\n",
    "  res=re.split(\"[/.]\",fname)[-2]\n",
    "  subname.append(res) \n",
    "\n",
    "subname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hr_gan(image_file):\n",
    "  image = tf.io.read_file(image_file)\n",
    "  image = tf.image.decode_png(image)[:,:,:3]\n",
    "\n",
    "  \n",
    "  real_image = tf.cast(image, tf.float32)\n",
    "  real_image=tf.reshape(real_image,[IMG_WIDTH,IMG_HEIGHT,3])\n",
    "  \n",
    "  return real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_hr_gan(image):\n",
    "  image=load_hr_gan(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gan='/home/hzhuge/Downloads/SR_2D/patch_result/gan_result'\n",
    "filename=subname[0]+'.png'\n",
    "PATH=os.path.join(path_gan,filename)\n",
    "test_gan = preprocess_image_hr_gan(PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_mse_mi_kidney(model, test_input,index):\n",
    "  # the training=True is intentional here since\n",
    "  # we want the batch statistics while running the model\n",
    "  # on the test dataset. If we use training=False, we will get\n",
    "  # the accumulated statistics learned from the training dataset\n",
    "  # (which we don't want)\n",
    "#   filename_cnn=subname[index]+'.png'\n",
    "#   directory_predict_unet = r'/home/hzhuge/Downloads/CSBDeep-master/examples/denoising2D/phantom_data/predict'  \n",
    "#   unet=tf.image.decode_image(tf.io.read_file(unet_name))\n",
    "#   unet = tf.expand_dims(tf.cast(unet[:,:,0], tf.float32),axis=2)\n",
    "\n",
    "\n",
    "  prediction = model(test_input, training=True)\n",
    "  print(prediction.shape)\n",
    "  plt.figure(figsize=(20,20))\n",
    "  \n",
    " \n",
    "  filename='PRE_'+subname[index]+'.png'\n",
    "  path_hr='/home/hzhuge/Downloads/SR_2D/cycgan_patch/kidney/patch_256'\n",
    "  PATH=os.path.join(path_hr,filename)\n",
    "  test_hr = preprocess_image_hr(PATH)\n",
    "  \n",
    "  filename=subname[index]+'.png'\n",
    "  path_gan='/home/hzhuge/Downloads/SR_2D/patch_result/gan_result'\n",
    "  PATH=os.path.join(path_gan,filename)\n",
    "  test_gan = preprocess_image_hr_gan(PATH) \n",
    "    \n",
    "  display_list = [test_input[0], test_hr, prediction[0],test_gan]\n",
    "  title = ['Gaussian', 'Ground Truth', 'Predicted Image_CycleGAN','Predicted Image_GAN']\n",
    "  inputim_l=np.array(display_list[0]*0.5+0.5)\n",
    "  ground_l=np.array(display_list[1]*0.5+0.5)\n",
    "  predict_l=np.array(display_list[2]*0.5+0.5)\n",
    "  cnn_l=np.array(display_list[3]*0.5+0.5)\n",
    "  \n",
    "  inputim_g= display_list[0]*0.5+0.5\n",
    "  ground_g = display_list[1]*0.5+0.5\n",
    "  predict_g = display_list[2]*0.5+0.5\n",
    "  cnn_g = display_list[3]*0.5+0.5\n",
    "  \n",
    "# sim vs. wide-field\n",
    "  mgi=np.square(np.subtract(ground_l, inputim_l)).mean()\n",
    "  sgi=tf.image.ssim(ground_g,inputim_g, max_val=1.0).numpy()\n",
    "  hist_2d_gi, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gi=mutual_information(hist_2d_gi)\n",
    "    \n",
    "# sim vs. gan\n",
    "  mgp=np.square(np.subtract(ground_l, predict_l)).mean()\n",
    "  sgp=tf.image.ssim(ground_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_gp, x_edges, y_edges = np.histogram2d(predict_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gp=mutual_information(hist_2d_gp)\n",
    "\n",
    "# sim vs. cnn\n",
    "  mgc=np.square(np.subtract(ground_l, cnn_l)).mean()\n",
    "  sgc=tf.image.ssim(ground_g,cnn_g, max_val=1.0).numpy()\n",
    "  hist_2d_gc, x_edges, y_edges = np.histogram2d(cnn_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gc=mutual_information(hist_2d_gc)\n",
    "\n",
    "# wide_field vs.gan\n",
    "  mip=np.square(np.subtract(inputim_l, predict_l)).mean()\n",
    "  sip=tf.image.ssim(inputim_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_ip, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),predict_l.ravel(),bins=20)\n",
    "  mi_ip=mutual_information(hist_2d_ip)\n",
    "\n",
    "# wide_field vs.cnn\n",
    "  mic=np.square(np.subtract(inputim_l, cnn_l)).mean()\n",
    "  sic=tf.image.ssim(inputim_g,cnn_g, max_val=1.0).numpy()\n",
    "  hist_2d_ic, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),cnn_l.ravel(),bins=20)\n",
    "  mi_ic=mutual_information(hist_2d_ic)\n",
    "\n",
    "# gan vs.cnn\n",
    "  mpc=np.square(np.subtract(predict_l, cnn_l)).mean()\n",
    "  spc=tf.image.ssim(predict_g,cnn_g, max_val=1.0).numpy()\n",
    "  hist_2d_pc, x_edges, y_edges = np.histogram2d(predict_l.ravel(),cnn_l.ravel(),bins=20)\n",
    "  mi_pc=mutual_information(hist_2d_pc)\n",
    "\n",
    "#  df = pd.DataFrame(np.array([mgi,mgp,mip,sgi,sgp,sip]), columns =['mse_ground_input','mse_ground_predict','mse_input_predict','ssim_ground_input',\n",
    "#           'ssim_ground_predict','ssim_input_predict']) \n",
    "  d={\n",
    "     \n",
    "     'MSE_HR_CycleGAN':mgp,\n",
    "     'MSE_HR_GAN':mgc, \n",
    "     'MSE_HR_Gaussian':mgi,\n",
    "     'MSE_GAN_CycleGAN':mpc,\n",
    "     'MSE_Gaussian_CycleGAN':mip,\n",
    "     'MSE_Gaussian_GAN':mic,\n",
    "    \n",
    "     'SSIM_HR_CycleGAN':sgp,\n",
    "     'SSIM_HR_GAN':sgc, \n",
    "     'SSIM_HR_Gaussian':sgi,\n",
    "     'SSIM_GAN_CycleGAN':spc,\n",
    "     'SSIM_Gaussian_CycleGAN':sip,\n",
    "     'SSIM_Gaussian_GAN':sic,\n",
    "    \n",
    "     'MI_HR_CycleGAN':mi_gp,\n",
    "     'MI_HR_GAN':mi_gc,\n",
    "     'MI_HR_Gaussian':mi_gi,\n",
    "     'MI_GAN_CycleGAN':mi_pc,\n",
    "     'MI_Gaussian_CycleGAN':mi_ip,\n",
    "     'MI_Gaussian_GAN':mi_ic\n",
    "     }\n",
    "#   d={'MSE_HR_GAN':mgp,\n",
    "#      'MSE_LR_GAN':mip,\n",
    "#      'MSE_LR_HR':mgi,\n",
    "#      'SSIM_HR_GAN':sgp,\n",
    "#      'SSIM_LR_GAN':sip,\n",
    "#      'SSIM_LR_HR':sgi,\n",
    "#      'MI_HR_GAN':mi_gp,\n",
    "#      'MI_LR_GAN':mi_ip,\n",
    "#      'MI_LR_HR':mi_gi}\n",
    "  ps1=pd.Series(d).to_frame().T\n",
    "  ps=pd.Series(d)\n",
    "  \n",
    "\n",
    "  for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "    \n",
    "\n",
    "  print(ps)\n",
    "  return ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "i=0\n",
    "df=pd.DataFrame()\n",
    "# Run the trained model on the test dataset\n",
    "for inp in test_dataset_lr.take(30):\n",
    "  ps=ssim_mse_mi_kidney(generator_g, inp,i)\n",
    "  df_temp=pd.DataFrame(ps)\n",
    "  df=df.append(df_temp)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(model, test_input,index):\n",
    "  prediction = model(test_input)\n",
    "  temp=prediction[0]*0.5+0.5\n",
    "  filename=subname[index]+'.png'\n",
    "  path_save='/home/hzhuge/Downloads/SR_2D/patch_result/SR-CycleGAN-kidney'\n",
    "  PATH=os.path.join(path_save,filename)\n",
    "  plt.imsave(PATH,temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp in test_dataset_lr:\n",
    "  sample_lr_up=tf.image.resize(inp,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "  save_images(generator_g, sample_lr_up,i)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIlinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_bilinear(test_input,index):\n",
    "  sample_lr_up=tf.image.resize(test_input[0],[256,256],antialias=True,method=tf.image.ResizeMethod.BILINEAR)\n",
    "  temp=sample_lr_up*0.5+0.5\n",
    "  filename=subname[index]+'.png'\n",
    "  path_save='/home/hzhuge/Downloads/SR_2D/patch_result/bilinear-kidney'\n",
    "  PATH=os.path.join(path_save,filename)\n",
    "  plt.imsave(PATH,temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp in test_dataset_lr:\n",
    "  save_images_bilinear(inp,i)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/home/hzhuge/Downloads/SR_2D/cycgan_patch/liver/patch_64'\n",
    "PATH=os.path.join(datadir)\n",
    "\n",
    "test_dataset_lr_name = tf.data.Dataset.list_files(PATH+'/*.png',shuffle=False)\n",
    "test_dataset_lr = test_dataset_lr_name.map(preprocess_image_lr,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset_lr = test_dataset_lr.batch(1)\n",
    "test_dataset_lr\n",
    "\n",
    "import re\n",
    "subname=list()\n",
    "for filename in test_dataset_lr_name:\n",
    "  fname=filename.numpy().decode('utf-8')\n",
    "  res=re.split(\"[/.]\",fname)[-2]\n",
    "  subname.append(res) \n",
    "\n",
    "subname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_mse_mi(model, test_input,index):\n",
    "  # the training=True is intentional here since\n",
    "  # we want the batch statistics while running the model\n",
    "  # on the test dataset. If we use training=False, we will get\n",
    "  # the accumulated statistics learned from the training dataset\n",
    "  # (which we don't want)\n",
    "#   filename_cnn=subname[index]+'.png'\n",
    "#   directory_predict_unet = r'/home/hzhuge/Downloads/CSBDeep-master/examples/denoising2D/phantom_data/predict'  \n",
    "#   unet=tf.image.decode_image(tf.io.read_file(unet_name))\n",
    "#   unet = tf.expand_dims(tf.cast(unet[:,:,0], tf.float32),axis=2)\n",
    "\n",
    "\n",
    "  prediction = model(test_input, training=True)\n",
    "  print(prediction.shape)\n",
    "  plt.figure(figsize=(20,20))\n",
    "  \n",
    " \n",
    "  filename=subname[index]+'.png'\n",
    "  path_hr='/home/hzhuge/Downloads/SR_2D/cycgan_patch/liver/patch_256'\n",
    "  PATH=os.path.join(path_hr,filename)\n",
    "  test_hr = preprocess_image_hr(PATH)\n",
    "\n",
    "\n",
    "    \n",
    "  display_list = [test_input[0], test_hr, prediction[0]]\n",
    "  title = ['Gaussian', 'Ground Truth', 'Predicted Image_CycleGAN']\n",
    "  inputim_l=np.array(display_list[0]*0.5+0.5)\n",
    "  ground_l=np.array(display_list[1]*0.5+0.5)\n",
    "  predict_l=np.array(display_list[2]*0.5+0.5)\n",
    "  \n",
    "  \n",
    "  inputim_g= display_list[0]*0.5+0.5\n",
    "  ground_g = display_list[1]*0.5+0.5\n",
    "  predict_g = display_list[2]*0.5+0.5\n",
    " \n",
    "  \n",
    "# sim vs. wide-field\n",
    "  mgi=np.square(np.subtract(ground_l, inputim_l)).mean()\n",
    "  sgi=tf.image.ssim(ground_g,inputim_g, max_val=1.0).numpy()\n",
    "  hist_2d_gi, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gi=mutual_information(hist_2d_gi)\n",
    "    \n",
    "# sim vs. gan\n",
    "  mgp=np.square(np.subtract(ground_l, predict_l)).mean()\n",
    "  sgp=tf.image.ssim(ground_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_gp, x_edges, y_edges = np.histogram2d(predict_l.ravel(),ground_l.ravel(),bins=20)\n",
    "  mi_gp=mutual_information(hist_2d_gp)\n",
    "\n",
    "\n",
    "# wide_field vs.gan\n",
    "  mip=np.square(np.subtract(inputim_l, predict_l)).mean()\n",
    "  sip=tf.image.ssim(inputim_g,predict_g, max_val=1.0).numpy()\n",
    "  hist_2d_ip, x_edges, y_edges = np.histogram2d(inputim_l.ravel(),predict_l.ravel(),bins=20)\n",
    "  mi_ip=mutual_information(hist_2d_ip)\n",
    "\n",
    "\n",
    "#  df = pd.DataFrame(np.array([mgi,mgp,mip,sgi,sgp,sip]), columns =['mse_ground_input','mse_ground_predict','mse_input_predict','ssim_ground_input',\n",
    "#           'ssim_ground_predict','ssim_input_predict']) \n",
    "  d={\n",
    "     \n",
    "     'MSE_HR_CycleGAN':mgp,\n",
    "     'MSE_HR_Gaussian':mgi,\n",
    "     'MSE_Gaussian_CycleGAN':mip,\n",
    "    \n",
    "     'SSIM_HR_CycleGAN':sgp,\n",
    "     'SSIM_HR_Gaussian':sgi,\n",
    "     'SSIM_Gaussian_CycleGAN':sip,\n",
    "    \n",
    "     'MI_HR_CycleGAN':mi_gp,\n",
    "     'MI_HR_Gaussian':mi_gi,\n",
    "     'MI_Gaussian_CycleGAN':mi_ip,\n",
    "     }\n",
    "#   d={'MSE_HR_GAN':mgp,\n",
    "#      'MSE_LR_GAN':mip,\n",
    "#      'MSE_LR_HR':mgi,\n",
    "#      'SSIM_HR_GAN':sgp,\n",
    "#      'SSIM_LR_GAN':sip,\n",
    "#      'SSIM_LR_HR':sgi,\n",
    "#      'MI_HR_GAN':mi_gp,\n",
    "#      'MI_LR_GAN':mi_ip,\n",
    "#      'MI_LR_HR':mi_gi}\n",
    "  ps1=pd.Series(d).to_frame().T\n",
    "  ps=pd.Series(d)\n",
    "  \n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "    \n",
    "\n",
    "  print(ps)\n",
    "  return ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "i=0\n",
    "df=pd.DataFrame()\n",
    "# Run the trained model on the test dataset\n",
    "for inp in test_dataset_lr.take(50):\n",
    "  sample_lr_up=tf.image.resize(inp,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "  ps=ssim_mse_mi(generator_g, sample_lr_up,i)\n",
    "  df_temp=pd.DataFrame(ps)\n",
    "  df=df.append(df_temp)\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(model, test_input,index):\n",
    "  prediction = model(test_input)\n",
    "  temp=prediction[0]*0.5+0.5\n",
    "  filename=subname[index]+'.png'\n",
    "  path_save='/home/hzhuge/Downloads/SR_2D/patch_result/liver/SR-CycleGAN-k'\n",
    "  PATH=os.path.join(path_save,filename)\n",
    "  plt.imsave(PATH,temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for inp in test_dataset_lr:\n",
    "  sample_lr_up=tf.image.resize(inp,[256,256],antialias=True,method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "  save_images(generator_g, sample_lr_up,i)\n",
    "  i=i+1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tfnew",
   "language": "python",
   "name": "tfnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
