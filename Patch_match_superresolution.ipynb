{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note on mac or linux: change backslash direction and remove double backslash \n",
    "pathf_5x = \n",
    "pathf_10x =\n",
    "pathf_20x ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import WSI\n",
    "wsi_5x = cv2.imread(pathf_5x + '5x.tif')\n",
    "wsi_10x = cv2.imread(pathf_10x + '10x.tif')\n",
    "wsi_20x = cv2.imread(pathf_20x + '20x.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wsi_20x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Small crop match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test matching between 5x and 20x for small cropped sections. Keep parameters associated with best match \n",
    "count = 0 \n",
    "best_quality = 0 #match quality \n",
    "while count< 150: #check 100 cropped sections\n",
    "    figure20, final_factor20,x,y,x20,y20, quality20, matches20 =scaleFind(wsi_5x, wsi_20x, 'SIFT', resize_factor=0.25,ratio=0.75,reprojThresh=0.5)\n",
    "    if (quality20 > best_quality) and (matches20 >greatest_matches): \n",
    "        x_final = x20  \n",
    "        y_final = y20\n",
    "        final_factor3 = final_factor20 \n",
    "        best_quality = quality20 \n",
    "    count = count +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save best match parameters\n",
    "final_factor_20 = final_factor3\n",
    "global_shiftx_20 = x_final*10    \n",
    "global_shifty_20 = y_final*10  \n",
    "print('*******COPY TO MATLAB********')\n",
    "print('global_shiftx_20=',global_shiftx_20)\n",
    "print('global_shifty_20=',global_shifty_20)\n",
    "print('final_factor_20=',final_factor_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual match check \n",
    "#Transparent overlay allows you to see if images are aligned \n",
    "buffer = 200\n",
    "buffer2 =100\n",
    "width = wsi_5x.shape[0] +buffer \n",
    "height = wsi_5x.shape[1] +buffer \n",
    "wsi_20x_resize3 = cv2.resize(wsi_20x,(np.int(wsi_20x.shape[1]*final_factor_20),np.int(wsi_20x.shape[0]*final_factor_20)))\n",
    "\n",
    "result1= np.zeros((width, height, 3), np.uint8)\n",
    "result2= np.zeros((width, height, 3), np.uint8)\n",
    "\n",
    "result1[buffer2 :wsi_5x.shape[0]+buffer2, buffer2:wsi_5x.shape[1]+buffer2] = wsi_5x\n",
    "result2[buffer2 +np.int(global_shifty_20/10):buffer2+wsi_20x_resize3.shape[0] + np.int(global_shifty_20/10), buffer2+np.int(global_shiftx_20/10):buffer2+wsi_20x_resize3.shape[1] + np.int(global_shiftx_20/10)] = wsi_20x_resize3 \n",
    "\n",
    "dst = cv2.addWeighted(result1,0.5,result2,0.5,0)\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(pathf_20x +'result.tiff',dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFind(imgA, imgB, method, resize_factor,ratio=0.75, reprojThresh=0.5):\n",
    "    #imgA is the low resolution image (5x) \n",
    "    #imgB is the higher resolution image (10x)\n",
    "    #resize factor = 0.5 for 10x to 5x match \n",
    "    #height and width of cropped image \n",
    "    height_A = 600 \n",
    "    width_A = 600\n",
    "    \n",
    "    #top left corner of crop, random start position\n",
    "    random.seed(a=None, version=2)\n",
    "    startx_A = random.randrange(400,imgA.shape[1]-width_A-400) \n",
    "    starty_A = random.randrange(400,imgA.shape[1]-height_A-400) \n",
    "\n",
    "    imgA_crop = imgA[starty_A:height_A+starty_A,startx_A:width_A+startx_A]\n",
    "\n",
    "    #resize 10x \n",
    "    imgB_resize = cv2.resize(imgB,(np.int(imgB.shape[1]*resize_factor),np.int(imgB.shape[0]*resize_factor)))\n",
    "    height_B = np.int(height_A*0.75)\n",
    "    width_B = np.int(width_A*0.75)\n",
    "    startx_B = startx_A  \n",
    "    starty_B = starty_A  \n",
    "    imgB_crop = imgB_resize[starty_B:height_B+starty_B,startx_B:width_B+startx_B]\n",
    "\n",
    "    #First find scale [1]\n",
    "    (factor, matches, status, H,theta)= returnScale(imgB_crop,imgA_crop,  'SIFT', ratio=0.75, reprojThresh=0.5)\n",
    "    \n",
    "    new_factor = resize_factor*factor\n",
    "    imgB_resize2 = cv2.resize(imgB,(np.int(imgB.shape[1]*new_factor),np.int(imgB.shape[0]*new_factor)))\n",
    "    imgB_crop = imgB_resize2[starty_B:height_B+starty_B,startx_B:width_B+startx_B]\n",
    "    (factor, matches, status, H,theta)= returnScale(imgB_crop,imgA_crop,  'SIFT', ratio=0.75, reprojThresh=0.5)\n",
    "    final_factor = factor*new_factor\n",
    "                                    \n",
    "    #x and y shift \n",
    "    x = np.int(H[0,2]) \n",
    "    y = np.int(H[1,2]) \n",
    "    \n",
    "    x2 = H[0,2]\n",
    "    y2 = H[1,2] \n",
    "\n",
    "    #stitch resized image \n",
    "    figure_stitch = stitchMosaics(imgA_crop, imgB_crop, x, y)\n",
    "#     plt.show()\n",
    "#     plt.imshow(figure_stitch)\n",
    "\n",
    "    quality = np.sum(status)/len(matches)                            \n",
    "    return figure_stitch, final_factor,x,y,x2,y2, quality, len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnScale(imgA, imgB, method, ratio=0.75, reprojThresh=1.0):\n",
    "    (kpsA, featuresA) = detectAndDescribe(imgA)\n",
    "    (kpsB, featuresB) = detectAndDescribe(imgB)\n",
    "\n",
    "    matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "\n",
    "    # perform K-NN matching between the 2 feature vector sets, using k= 2\n",
    "    rawMatches = matcher.knnMatch(featuresA, featuresB, 2)\n",
    "    matches = []\n",
    "\n",
    "    # loop over the raw matches to prune false positives\n",
    "    for m in rawMatches:\n",
    "        # ensure the distance is within a certain ratio of each\n",
    "        # other (i.e. Lowe's ratio test)\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "            # item.trainIdx: This attribute gives us the index of the descriptor in the list of train descriptors (the list of descriptors in the img2).\n",
    "            # item.queryIdx: This attribute gives us the index of the descriptor in the list of query descriptors (the list of descriptors in the img1).\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "    if len(matches) > 4:\n",
    "        # construct the two sets of points\n",
    "        ptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
    "        ptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
    "\n",
    "    (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "    a = H[0, 0]\n",
    "    b = H[0, 1]\n",
    "    d = H[1, 0]\n",
    "    e = H[1, 1]\n",
    "    p = math.sqrt(a ** 2 + b ** 2)\n",
    "    factor = (a * e + b * d) / p\n",
    "    theta = math.atan2(H[0,1],H[0,0])*180/math.pi\n",
    "\n",
    "    return factor, matches, status, H, theta\n",
    "\n",
    "def detectAndDescribe(image):\n",
    "    \"\"\"detects keypoints and extracts local invariant descriptors\"\"\"\n",
    "\n",
    "    descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # detectAndCompute -- extracts keypoints and features, Detects keypoints and computes the descriptors\n",
    "    (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "\n",
    "    if features is None or kps is None:\n",
    "        return (None, None)\n",
    "\n",
    "    else:\n",
    "        kps = np.float32([kp.pt for kp in kps])\n",
    "        return (kps, features)\n",
    "    \n",
    "def stitchMosaics(imageA, imageB, x, y):\n",
    "    width = imageA.shape[0] +100\n",
    "    height = imageA.shape[1] +100\n",
    "\n",
    "    result_stitch = np.zeros((width, height, 3), np.uint8)\n",
    "    shiftx = x+50\n",
    "    shifty = y+50\n",
    "\n",
    "    result_stitch[50:imageA.shape[0]+50, 50:imageA.shape[1]+50] = imageA\n",
    "    roi = result_stitch[shifty:imageB.shape[0] + shifty, shiftx:imageB.shape[1] + shiftx]\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    img2gray = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "    img2_fg = cv2.bitwise_and(imageB, imageB, mask=mask)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    dst = cv2.add(img1_bg, img2_fg)\n",
    "    result_stitch[shifty:imageB.shape[0] + shifty, shiftx:imageB.shape[1] + shiftx] = dst\n",
    "\n",
    "    # return the stitched image\n",
    "    return result_stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
